{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40bad51d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'img_to_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 519\u001b[0m, in \u001b[0;36mFaceApp.update_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognize_enabled):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# Recognize\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     detected_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayImage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 478\u001b[0m, in \u001b[0;36mFaceApp.recognize\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattendance(name, label)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotionButton\u001b[38;5;241m.\u001b[39misChecked():\n\u001b[0;32m--> 478\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_rectangle(frame, top, right,\n\u001b[1;32m    481\u001b[0m                         bottom, left, color, emotion)\n",
      "Cell \u001b[0;32mIn[1], line 311\u001b[0m, in \u001b[0;36mFaceApp.predict_emotion\u001b[0;34m(self, face_roi)\u001b[0m\n\u001b[1;32m    309\u001b[0m face_roi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_roi, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Array\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m(face_roi)\n\u001b[1;32m    312\u001b[0m img_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_pixels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    313\u001b[0m img_pixels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'img_to_array'"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 567\u001b[0m\n\u001b[1;32m    564\u001b[0m window\u001b[38;5;241m.\u001b[39msetWindowTitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace App\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m window\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m--> 567\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit(\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "from PyQt5 import QtGui, QtCore, QtSql\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer\n",
    "from PyQt5.QtWidgets import QDialog, QApplication, QMainWindow, QMessageBox, QInputDialog, QFileDialog, QPushButton, QDialogButtonBox, QTableWidgetItem\n",
    "from PyQt5.uic import loadUi\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import face_recognition\n",
    "import dlib\n",
    "import time\n",
    "from datetime import datetime\n",
    "from PyQt5.QtSql import QSqlDatabase\n",
    "\n",
    "\n",
    "# Dialog box for entering name and key of new dataset.\n",
    "class USER(QDialog):\n",
    "    \"\"\"USER Dialog \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(USER, self).__init__()\n",
    "        loadUi(\"GUI/showUsers.ui\", self)\n",
    "\n",
    "        self.source_path = \"\"\n",
    "        self.name = \"\"\n",
    "        self.extension = '.jpg'\n",
    "\n",
    "        self.uploadphotoButton.clicked.connect(self.open_file)\n",
    "        self.saveButton.clicked.connect(self.save)\n",
    "        self.saveButton.clicked.connect(self.show_users)\n",
    "        self.removeButton.clicked.connect(self.remove_users)\n",
    "        self.listWidget.clicked.connect(self.preview_image)\n",
    "\n",
    "        self.path = 'media/faces'\n",
    "\n",
    "        self.show_users()\n",
    "\n",
    "    def open_file(self):\n",
    "        self.source_path = QFileDialog.getOpenFileName()\n",
    "        self.source_path = self.source_path[0]\n",
    "        thumbnail = QPixmap(self.source_path)\n",
    "        thumbnail = thumbnail.scaled(120, 120)\n",
    "\n",
    "        self.userPhoto.setPixmap(thumbnail)\n",
    "        if self.source_path.endswith('.jpg') or self.source_path.endswith('.png'):\n",
    "            file, self.extension = self.source_path.split('.')\n",
    "\n",
    "    def save(self):\n",
    "        self.name = self.nameInput.text()\n",
    "        if self.source_path != \"\":\n",
    "            if self.name != \"\":\n",
    "                img = cv2.imread(self.source_path)\n",
    "                newPath = self.path + '/' + self.name + '.' + self.extension\n",
    "                cv2.imwrite(newPath, img)\n",
    "            else:\n",
    "                QMessageBox().about(self, \"Warning\", \"Bitte geben Sie einen Namen ein.\")\n",
    "        else:\n",
    "            QMessageBox().about(self, \"Warning\", \"Bitte fügen Sie ein Foto hinzu.\")\n",
    "\n",
    "    def show_users(self):\n",
    "        files = [x for x in os.listdir(self.path)]\n",
    "        for index, file in enumerate(files):\n",
    "            if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                self.listWidget.takeItem(index)\n",
    "                self.listWidget.insertItem(index, file)\n",
    "\n",
    "    def remove_users(self):\n",
    "        item = self.listWidget.currentItem()\n",
    "        os.remove(self.path + '/' + item.text())\n",
    "        QMessageBox().about(self, \"Warning\", \"{} is gelöscht.\".format(item.text()))\n",
    "\n",
    "    def preview_image(self):\n",
    "        item = self.listWidget.currentItem()\n",
    "        path = self.path + '/' + item.text()\n",
    "        thumbnail = QPixmap(path)\n",
    "        thumbnail = thumbnail.scaled(120, 120)\n",
    "        self.userPhoto.setPixmap(thumbnail)\n",
    "\n",
    "\n",
    "class FaceApp(QMainWindow):        # Main application\n",
    "    \"\"\"Main Class\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FaceApp, self).__init__()\n",
    "        loadUi(\"GUI/faceApp.ui\", self)\n",
    "\n",
    "        self.startButton.setCheckable(True)\n",
    "        self.startButton.toggled.connect(self.start_webcam)\n",
    "\n",
    "        self.detectButton.setCheckable(True)\n",
    "        self.detectButton.toggled.connect(self.recognize_button)\n",
    "\n",
    "        self.nameButton.setChecked(True)\n",
    "        self.maskButton.setChecked(False)\n",
    "        self.emotionButton.setChecked(False)\n",
    "        self.genderButton.setChecked(False)\n",
    "        self.ageButton.setChecked(False)\n",
    "        self.blurButton.setChecked(False)\n",
    "        self.faceLandmarksButton.setChecked(False)\n",
    "\n",
    "        self.openVideoButton.clicked.connect(self.open_video)\n",
    "\n",
    "        self.saveimageButton.clicked.connect(self.save_image)\n",
    "\n",
    "        self.exitButton.clicked.connect(QApplication.instance().quit)\n",
    "\n",
    "        self.webcam_Enabled = False\n",
    "        self.recognize_enabled = False\n",
    "        # self.record_Enabled = False\n",
    "\n",
    "        self.ret = False\n",
    "        self.source_camera = 0\n",
    "\n",
    "        self.image = cv2.imread(\"GUI/Icon.png\", 1)\n",
    "\n",
    "        # Recognize\n",
    "        self.userPath = 'media/faces'\n",
    "        self.usersList = [i for i in os.listdir(\n",
    "            self.userPath) if i.endswith('.jpg') or i.endswith('.png')]\n",
    "        self.usersImgs, self.usersNames = self.list_userImg_userName(\n",
    "            self.usersList, self.userPath)\n",
    "        self.encodeListKnown = self.findEncodings()\n",
    "\n",
    "        # Emotion\n",
    "        self.face_exp_model = model_from_json(\n",
    "            open('models/facial_expression_model_structure.json', 'r').read())\n",
    "        self.face_exp_model.load_weights(\n",
    "            'models/facial_expression_model_weights.h5')\n",
    "        self.emotions_labels = ('angry', 'disgusted', \"\",\n",
    "                                'lucky', 'Sad', 'surprise', 'Neutral')\n",
    "\n",
    "        # Gender\n",
    "        self.gender_label_list = [\"Male\", \"Female\"]\n",
    "        self.gender_protext = \"models/gender_deploy.prototxt\"\n",
    "        self.gender_caffemodel = \"models/gender_net.caffemodel\"\n",
    "        self.gender_cov_net = cv2.dnn.readNet(\n",
    "            self.gender_caffemodel, self.gender_protext)\n",
    "        # Age\n",
    "        self.AGE_GENDER_MODEL_MEAN_VALUES = (\n",
    "            78.4263377603, 87.7689143744, 114.895847746)\n",
    "        self.age_label_list = ['0-2', '4-6', '8-12',\n",
    "                               '15-20', '25-32', '38-43', '48-53', '60-100']\n",
    "        self.age_protext = \"models/age_deploy.prototxt\"\n",
    "        self.age_caffemodel = \"models/age_net.caffemodel\"\n",
    "        self.age_cov_net = cv2.dnn.readNet(\n",
    "            self.age_caffemodel, self.age_protext)\n",
    "\n",
    "        # Mask detection\n",
    "        self.prototxtPath = \"models/deploy.prototxt\"\n",
    "        self.weightsPath = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "        self.faceNet = cv2.dnn.readNet(self.prototxtPath, self.weightsPath)\n",
    "        self.maskNet = load_model(\"models/mask_detector.model\")\n",
    "\n",
    "        # Face Landmarks\n",
    "        # Load the detector\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "        # Load the predictor\n",
    "        self.predictor = dlib.shape_predictor(\n",
    "            \"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "        # GUI\n",
    "        self.adduserButton.clicked.connect(self.users_dialog)\n",
    "\n",
    "        self.loadButton.clicked.connect(self.load_db)\n",
    "\n",
    "        self.facecount = \"0\"\n",
    "\n",
    "        self.path = 'media/faces'\n",
    "        self.usersName = []\n",
    "\n",
    "    def open_video(self):\n",
    "        self.source_camera = QFileDialog.getOpenFileName()\n",
    "        self.source_camera = self.source_camera[0]\n",
    "        self.capture = cv2.VideoCapture(self.source_camera)\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(5)\n",
    "\n",
    "    #### GUI ####\n",
    "\n",
    "    def preview_image(self):\n",
    "\n",
    "        names = list(set(self.usersName))\n",
    "\n",
    "        if len(names) >= 1:\n",
    "\n",
    "            name1 = names[0]\n",
    "            path = self.path + '/' + str(name1) + '.jpg'\n",
    "            thumbnail1 = QPixmap(path)\n",
    "            thumbnail1 = thumbnail1.scaled(100, 90)\n",
    "            self.userPhoto1.setPixmap(thumbnail1)\n",
    "            self.userName1.setText(name1)\n",
    "\n",
    "        if len(names) >= 2:\n",
    "            name1 = names[0]\n",
    "            path = self.path + '/' + str(name1) + '.jpg'\n",
    "            thumbnail1 = QPixmap(path)\n",
    "            thumbnail1 = thumbnail1.scaled(100, 90)\n",
    "            self.userPhoto1.setPixmap(thumbnail1)\n",
    "\n",
    "            name2 = names[1]\n",
    "            path = self.path + '/' + str(name2) + '.jpg'\n",
    "            thumbnail2 = QPixmap(path)\n",
    "            thumbnail2 = thumbnail2.scaled(100, 90)\n",
    "            self.userPhoto2.setPixmap(thumbnail2)\n",
    "            self.userName2.setText(name2)\n",
    "\n",
    "    def load_db(self):\n",
    "        connection = sqlite3.connect('face.db')\n",
    "        query = \"SELECT mytime, mydate, name, mask FROM people ORDER BY person_id DESC\"\n",
    "        result = connection.execute(query)\n",
    "        self.dbTableWidget.setRowCount(0)\n",
    "\n",
    "        for row_number, row_data in enumerate(result):\n",
    "            self.dbTableWidget.insertRow(row_number)\n",
    "            for column_number, data in enumerate(row_data):\n",
    "                self.dbTableWidget.setItem(\n",
    "                    row_number, column_number, QTableWidgetItem(str(data)))\n",
    "        connection.close()\n",
    "\n",
    "    def users_dialog(self):\n",
    "        user = USER()\n",
    "        user.exec_()\n",
    "\n",
    "    def detect_face_mask(self, frame, faceNet, maskNet):\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        faceNet.setInput(blob)\n",
    "        detections = faceNet.forward()\n",
    "\n",
    "        faces = []\n",
    "        locs = []\n",
    "        preds = []\n",
    "\n",
    "        try:\n",
    "            # loop over the detections\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                if confidence > 0.5:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                    (startX, startY) = (max(0, startX), max(0, startY))\n",
    "                    (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "                    face = frame[startY:endY, startX:endX]\n",
    "                    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "                    face = cv2.resize(face, (224, 224))\n",
    "                    face = img_to_array(face)\n",
    "                    face = preprocess_input(face)\n",
    "                    faces.append(face)\n",
    "                    locs.append((startX, startY, endX, endY))\n",
    "\n",
    "            # only make a predictions if at least one face was detected\n",
    "            if len(faces) > 0:\n",
    "                faces = np.array(faces, dtype=\"float32\")\n",
    "                preds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "            return (locs, preds)\n",
    "\n",
    "        except:\n",
    "            print('Mask Detection Error')\n",
    "\n",
    "    def time(self):     # Get current time.\n",
    "        return datetime.now().strftime(\"%d-%b-%Y:%I-%M-%S\")\n",
    "\n",
    "    def list_userImg_userName(self, usersList, userPath):\n",
    "        usersImgs = []\n",
    "        usersNames = []\n",
    "        for user in usersList:\n",
    "            userImg = cv2.imread('{}/{}'.format(userPath, user))\n",
    "            usersImgs.append(userImg)\n",
    "            userName = os.path.splitext(user)[0]\n",
    "            usersNames.append(userName)\n",
    "        return usersImgs, usersNames\n",
    "\n",
    "    def predict_gender(self, face_roi):\n",
    "        face_roi_blob = cv2.dnn.blobFromImage(\n",
    "            face_roi, 1, (227, 227), self.AGE_GENDER_MODEL_MEAN_VALUES, swapRB=False)\n",
    "        self.gender_cov_net.setInput(face_roi_blob)\n",
    "        gender_predictions = self.gender_cov_net.forward()\n",
    "        gender = self.gender_label_list[gender_predictions[0].argmax()]\n",
    "        return gender\n",
    "\n",
    "    def predict_age(self, face_roi):\n",
    "        face_roi_blob = cv2.dnn.blobFromImage(\n",
    "            face_roi, 1, (227, 227), self.AGE_GENDER_MODEL_MEAN_VALUES, swapRB=False)\n",
    "        self.age_cov_net.setInput(face_roi_blob)\n",
    "        age_predictions = self.age_cov_net.forward()\n",
    "        age = self.age_label_list[age_predictions[0].argmax()]\n",
    "        return age\n",
    "\n",
    "    def predict_emotion(self, face_roi):\n",
    "        # Gray and resize\n",
    "        face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        face_roi = cv2.resize(face_roi, (48, 48))\n",
    "        # Array\n",
    "        img_pixels = image.img_to_array(face_roi)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "        img_pixels /= 255\n",
    "        # Predict\n",
    "        exp_predictions = self.face_exp_model.predict(img_pixels)\n",
    "        max_index = np.argmax(exp_predictions[0])\n",
    "        emotion = self.emotions_labels[max_index]\n",
    "        return emotion\n",
    "\n",
    "    def recognize_button(self, status):\n",
    "        if status:\n",
    "            self.detectButton .setText('Erkennung beenden')\n",
    "            self.recognize_enabled = True\n",
    "        else:\n",
    "            self.detectButton .setText('Gesicht erkennen')\n",
    "            self.recognize_enabled = False\n",
    "\n",
    "    def start_webcam(self, status):\n",
    "        if status:\n",
    "            camera = int(self.comboBox.currentText())\n",
    "            self.capture = cv2.VideoCapture(camera)\n",
    "            self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "            self.capture.set(cv2.CAP_PROP_FRAME_WIDTH,  640)\n",
    "            self.timer = QTimer(self)\n",
    "            self.timer.timeout.connect(self.update_frame)\n",
    "            self.timer.start(5)\n",
    "            self.startButton .setText('Stop')\n",
    "            self.webcam_Enabled = True\n",
    "        else:\n",
    "            self.startButton .setText('Webcam Starten')\n",
    "            self.webcam_Enabled = False\n",
    "            self.timer.stop()\n",
    "            self.ret = False\n",
    "            self.capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def known_faces(self, encodeFace):\n",
    "        all_matches = face_recognition.compare_faces(\n",
    "            self.encodeListKnown, encodeFace)\n",
    "        name = 'UNBEKANNT'\n",
    "        if True in all_matches:\n",
    "            first_match_index = all_matches.index(True)\n",
    "            name = self.usersNames[first_match_index].upper()\n",
    "        return name\n",
    "\n",
    "    def findEncodings(self):\n",
    "        encodeList = []\n",
    "        for img in self.usersImgs:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            encode = face_recognition.face_encodings(img)[0]\n",
    "            encodeList.append(encode)\n",
    "        return encodeList\n",
    "\n",
    "    def face_blur(self, face_roi):\n",
    "        face_roi_blur = cv2.GaussianBlur(face_roi, (99, 99), 30)\n",
    "        return face_roi_blur\n",
    "\n",
    "    def draw_face_landmarks(self, frame):\n",
    "        # Convert image into grayscale\n",
    "        gray = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2GRAY)\n",
    "        # Use detector to find landmarks\n",
    "        faces = self.detector(gray)\n",
    "\n",
    "        for face in faces:\n",
    "            # Create landmark object\n",
    "            landmarks = self.predictor(image=gray, box=face)\n",
    "\n",
    "            # Loop through all the points\n",
    "            for n in range(0, 68):\n",
    "                x = landmarks.part(n).x\n",
    "                y = landmarks.part(n).y\n",
    "\n",
    "                # Draw a circle\n",
    "                cv2.circle(img=frame, center=(x, y), radius=2,\n",
    "                           color=(255, 255, 0), thickness=-1)\n",
    "        # return frame\n",
    "\n",
    "    def draw_rectangle(self, frame, top, right, bottom, left, color, text):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "        cv2.rectangle(frame, (left, bottom-35),\n",
    "                      (right, bottom), color, cv2.FILLED)\n",
    "        cv2.putText(frame, text.upper(), (left+6, bottom-6),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    ##### DATABASE #####\n",
    "\n",
    "    def data_entry(self, connection, cursor,  name, mask, date, time):\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO people VALUES (NULL, ?, ?, ?, ?)\", (name, mask, date, time))\n",
    "        connection.commit()\n",
    "        print(name, mask, date, time)\n",
    "\n",
    "    def attendance(self, name, mask):\n",
    "        now = datetime.now()\n",
    "        date = str(now.strftime(\"%d/%m/%Y\"))\n",
    "        time = str(now.strftime(\"%H:%M:%S\"))\n",
    "        hour = time.split(\":\")[0]\n",
    "\n",
    "        try:\n",
    "            connection = sqlite3.connect(\"face.db\")\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(\n",
    "                \"SELECT name, mydate, mytime, mask FROM people  WHERE name=? ORDER BY person_id DESC LIMIT 1\", (name,))\n",
    "            row = cursor.fetchall()\n",
    "\n",
    "            if row == []:\n",
    "                self.data_entry(connection, cursor,  name, mask, date, time)\n",
    "            else:\n",
    "\n",
    "                dbName, dbDate, dbTime, dbMask = row[0]\n",
    "                dbHour = dbTime.split(\":\")[0]\n",
    "\n",
    "                if dbName == name and dbDate == date and dbHour == hour:\n",
    "                    pass\n",
    "                else:\n",
    "                    if name != 'UNBEKANNT':\n",
    "                        self.data_entry(connection, cursor,\n",
    "                                        name, mask, date, time)\n",
    "\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "            # print(\"Success DB\")\n",
    "        except:\n",
    "            print(\"Error DB\")\n",
    "\n",
    "    ##### Face Recognition Main Function #####\n",
    "\n",
    "    def recognize(self, frame):\n",
    "        frameSmall = cv2.resize(frame, (0, 0), None, 0.25, 0.25)\n",
    "        frameSmall = cv2.cvtColor(frameSmall, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        facesCurrentFrame = face_recognition.face_locations(\n",
    "            frameSmall, number_of_times_to_upsample=1, model='hog')\n",
    "        encodesCurrentFrame = face_recognition.face_encodings(\n",
    "            frameSmall, facesCurrentFrame)\n",
    "\n",
    "        self.facecount = str(len(facesCurrentFrame))\n",
    "        self.countLabel.setText(self.facecount)\n",
    "\n",
    "        if len(facesCurrentFrame) >= 1:\n",
    "            self.preview_image()\n",
    "\n",
    "        for encodeFace, faceLocation in zip(encodesCurrentFrame, facesCurrentFrame):\n",
    "            top, right, bottom, left = faceLocation\n",
    "            top, right, bottom, left = top*4, right*4, bottom*4, left*4\n",
    "            face_roi = frame[top:bottom, left:right]\n",
    "\n",
    "            name = self.known_faces(encodeFace)\n",
    "\n",
    "            if name != 'UNBEKANNT':\n",
    "                self.usersName.append(name)\n",
    "\n",
    "            if self.maskButton.isChecked():\n",
    "                locs, preds = self.detect_face_mask(\n",
    "                    frame, self.faceNet, self.maskNet)\n",
    "\n",
    "                for (box, pred) in zip(locs, preds):\n",
    "                    # left, top, right, botttom = box\n",
    "                    (mask, withoutMask) = pred\n",
    "                    label = \"Maske\" if mask > withoutMask else \"Keine Maske\"\n",
    "                    color = (0, 255, 0) if label == \"Maske\" else (0, 0, 255)\n",
    "                    self.draw_rectangle(frame, top, right,\n",
    "                                        bottom, left, color, label)\n",
    "                    self.attendance(name, label)\n",
    "\n",
    "            elif self.emotionButton.isChecked():\n",
    "                emotion = self.predict_emotion(face_roi)\n",
    "                color = (0, 0, 255)\n",
    "                self.draw_rectangle(frame, top, right,\n",
    "                                    bottom, left, color, emotion)\n",
    "\n",
    "            elif self.genderButton.isChecked():\n",
    "                gender = self.predict_gender(face_roi)\n",
    "                color = (0, 0, 255)\n",
    "                self.draw_rectangle(frame, top, right,\n",
    "                                    bottom, left, color, gender)\n",
    "\n",
    "            elif self.ageButton.isChecked():\n",
    "                age = self.predict_age(face_roi)\n",
    "                color = (0, 0, 255)\n",
    "                self.draw_rectangle(frame, top, right,\n",
    "                                    bottom, left, color, age)\n",
    "\n",
    "            elif self.blurButton.isChecked():\n",
    "                face_roi_blur = cv2.GaussianBlur(face_roi, (99, 99), 30)\n",
    "                frame[top:bottom, left:right] = face_roi_blur\n",
    "\n",
    "            elif self.faceLandmarksButton.isChecked():\n",
    "                self.draw_face_landmarks(frame)\n",
    "\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                self.draw_rectangle(frame, top, right,\n",
    "                                    bottom, left, color, name)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    ##### Video Frame #####\n",
    "\n",
    "    def update_frame(self):\n",
    "        self.ret, self.image = self.capture.read()\n",
    "        if self.ret:\n",
    "            self.image = cv2.flip(self.image, 1)\n",
    "            detected_image = None\n",
    "\n",
    "            if (self.recognize_enabled):\n",
    "                # Recognize\n",
    "                detected_image = self.recognize(self.image)\n",
    "                self.displayImage(self.image, 1)\n",
    "\n",
    "            else:\n",
    "                self.displayImage(detected_image, 1)\n",
    "\n",
    "    def displayImage(self, img, window=1):\n",
    "        pixImage = self.pix_image()\n",
    "        if window == 1:\n",
    "            self.imageLabel.setPixmap(QPixmap.fromImage(pixImage))\n",
    "            self.imageLabel.setScaledContents(True)\n",
    "\n",
    "    # Converting image from OpenCv to PyQT compatible image.\n",
    "\n",
    "    def pix_image(self):\n",
    "        qformat = QImage.Format_RGB888  # only RGB Image\n",
    "        if len(self.image.shape) == 3:\n",
    "            r, c, ch = self.image.shape\n",
    "        else:\n",
    "            r, c = self.image.shape\n",
    "            qformat = QImage.Format_Indexed8\n",
    "        pixImage = QImage(self.image, c, r, self.image.strides[0], qformat)\n",
    "        return pixImage.rgbSwapped()\n",
    "\n",
    "    ##### SAVE DATA #####\n",
    "    # Save image captured using the save button.\n",
    "\n",
    "    def save_image(self):\n",
    "        location = QFileDialog.getSaveFileName(self, 'Save File')\n",
    "        location = location[0]\n",
    "        # location =  location[0]\n",
    "        file_type = \".jpg\"\n",
    "        file_name = location+file_type\n",
    "        try:\n",
    "            cv2.imwrite(file_name, self.image)\n",
    "            QMessageBox().about(self, \"Image Saved\", \"Saved successfully at \"+file_name)\n",
    "        except:\n",
    "            print('Error Save Images')\n",
    "\n",
    "\n",
    "##### MAIN FUNCTION #####\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "\n",
    "    window = FaceApp()         # Running application loop.\n",
    "    window.setWindowTitle(\"Face App\")\n",
    "    window.show()\n",
    "\n",
    "    sys.exit(app.exec_())  # Exit applicatio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c25772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
